{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc33921f",
   "metadata": {},
   "source": [
    "# Electoral guardian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0548fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide dependencies \n",
    "! pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5827db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Dependencies \n",
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dcaf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ngrok(to make it possible to receive the webhook from Z-Api)\n",
    "! pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac6f66c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment initialization\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Optional\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import server\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load environment variables\n",
    "instance_id = os.getenv('API_INSTANCE_ZAPI')\n",
    "token = os.getenv('INSTANCE_TOKEN')\n",
    "phone_number = os.getenv('PHONE_NUMBER')\n",
    "client_token = os.getenv('CLIENT_TOKEN')\n",
    "\n",
    "# State definition\n",
    "class GuardianState(TypedDict):\n",
    "    media: Optional[bytes]\n",
    "    tipo: Optional[str]\n",
    "    analysis_result: Optional[dict]\n",
    "    reliability_index: Optional[int]\n",
    "    answer: Optional[str]\n",
    "\n",
    "# Node functions\n",
    "def receive_input(state: GuardianState) -> GuardianState:\n",
    "    \"\"\"Receives video from user via WhatsApp and downloads it\"\"\"\n",
    "    print(\"ğŸ“¥ Receiving video via Whatsapp\")\n",
    "\n",
    "    answer = (\n",
    "        f\"âš ï¸ Wait a minute, we are analysing your video..\\n\"\n",
    "    )\n",
    "\n",
    "    url = f\"https://api.z-api.io/instances/{instance_id}/token/{token}/send-text\"\n",
    "    payload = {\n",
    "        \"phone\": phone_number,  # user number\n",
    "        \"message\": answer\n",
    "    }\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0 Edg/124.0.2478.80\",\n",
    "        'client-token': client_token,\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload, timeout=10)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âŒ Error sending message:. {e}\")\n",
    "        answer = \"generate connection error with the remote server.\"\n",
    "\n",
    "    last_video_file = \"last_video.txt\"\n",
    "\n",
    "    # Parse the file and retrieve the most recent URL.\n",
    "    try:\n",
    "        with open(last_video_file, \"r\") as f:\n",
    "            video_url = f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        raise ValueError(\"URL file not found.\")\n",
    "\n",
    "    if not video_url:\n",
    "        raise ValueError(\"Video URL not provided.\")\n",
    "\n",
    "    print(f\"ğŸ¯ URL captured: {video_url}\")\n",
    "\n",
    "    try:\n",
    "        response = requests.get(video_url, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Failed to download the video: {response.status_code}\")\n",
    "        \n",
    "        print(f\"âœ… Video downloaded successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error downloading the video: {e}\")\n",
    "        raise e  # Here we let the error propagate for Graph to handle.\n",
    "\n",
    "    # Detect media type based on extension\n",
    "    if video_url.endswith((\".mp4\", \".mov\", \".avi\")):\n",
    "        tipo = \"video\"\n",
    "        file_path = \"input_video.mp4\"\n",
    "    else:\n",
    "        raise ValueError(\"âŒ Unsupported media format.\")\n",
    "\n",
    "    # Save the media on disk\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    print(f\"âœ… {tipo.capitalize()} saved as {file_path}\")\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"media\": file_path, \n",
    "        \"tipo\": tipo\n",
    "    }\n",
    "\n",
    "def process_media(state: GuardianState) -> GuardianState:\n",
    "    \"\"\"Process the input received.\"\"\"\n",
    "    print(f\"ğŸ§ª Processing {state['tipo']}...\")\n",
    "\n",
    "    frames_folder = \"frames\"\n",
    "    os.makedirs(frames_folder, exist_ok=True)\n",
    "\n",
    "    # Extract frames\n",
    "    cap = cv2.VideoCapture(state[\"media\"])\n",
    "    frame_idx = 0\n",
    "    saved_idx = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_idx % 30 == 0:\n",
    "            frame_path = os.path.join(frames_folder, f\"frame_{saved_idx}.jpg\")\n",
    "            # Save the frame and verify if there was valid\n",
    "            print(f\"Saving frame {saved_idx} how {frame_path}\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            saved_idx += 1\n",
    "        frame_idx += 1\n",
    "    cap.release()\n",
    "\n",
    "    frames = os.listdir(frames_folder)\n",
    "    if not frames:\n",
    "        raise RuntimeError(\"No frames were extracted from the video.\")\n",
    "\n",
    "    #Deepfake detection\n",
    "    deepfake_detector = pipeline(\"image-classification\", model=\"Wvolf/ViT_Deepfake_Detection\")\n",
    "\n",
    "    fake_scores = []\n",
    "    for frame_file in frames:\n",
    "        frame_path = os.path.join(frames_folder, frame_file)\n",
    "\n",
    "        # Resize the image to 224x224 before sending to the model\n",
    "        frame_image = Image.open(frame_path)\n",
    "        frame_image = frame_image.resize((224, 224))  \n",
    "        frame_image.save(frame_path)  \n",
    "\n",
    "        # Make the forecast\n",
    "        preds = deepfake_detector(frame_path)\n",
    "        print(f\"Predictions for {frame_path}: {preds}\")  \n",
    "\n",
    "        # Check if the 'Fake' class exists and extract the score\n",
    "        fake_score = 0\n",
    "        for item in preds:\n",
    "            if item['label'] == 'Fake':\n",
    "                fake_score = item['score']\n",
    "                break\n",
    "\n",
    "        print(f\"Deepfake score for {frame_path}: {fake_score}\")\n",
    "        fake_scores.append(fake_score)\n",
    "\n",
    "    # Calculate the average deepfake score\n",
    "    media_fake_score = sum(fake_scores) / len(fake_scores) if fake_scores else 0\n",
    "\n",
    "    # Calculate the reliability score\n",
    "    state['reliability_index'] = int(media_fake_score * 100)  # Atribuindo o Ã­ndice\n",
    "\n",
    "    # Clear the frames after processing\n",
    "    shutil.rmtree(frames_folder)\n",
    "\n",
    "    fake_result = media_fake_score > 0.5\n",
    "    explanation = f\"Average deepfake score: {media_fake_score:.2f}\"\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"analysis_result\": {\n",
    "            \"deepfake_detected\": fake_result,\n",
    "            \"explanation\": explanation\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def generate_answer(state: GuardianState) -> GuardianState:\n",
    "    \"\"\"Generates the answer for the user.\"\"\"\n",
    "    print(\"ğŸ“¤ Generating the answer for the user....\")\n",
    "    if 'reliability_index' not in state:\n",
    "        print(\"âŒ Key 'reliability_index' not found in state.\")\n",
    "        state['reliability_index'] = 0  # or any default value \n",
    "\n",
    "    answer = (\n",
    "        f\"âš ï¸ Alert: possible manipulation detected..\\n\"\n",
    "        f\"Reliability Index: {state['reliability_index']} / 100\\n\"\n",
    "        f\"Details: {state['analysis_result']['explanation']}\"\n",
    "        if state[\"reliability_index\"] < 75\n",
    "        else f\"âœ… No signs of manipulation.\\nReliability index: {state['reliability_index']} / 100\"\n",
    "    )\n",
    "    \n",
    "    # Send on WhatsApp \n",
    "    url = f\"https://api.z-api.io/instances/{instance_id}/token/{token}/send-video\"\n",
    "    payload = {\n",
    "        \"phone\": phone_number,  # user number\n",
    "        \"message\": answer\n",
    "    }\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0 Edg/124.0.2478.80\",\n",
    "        'client-token': client_token,\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload, timeout=10)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âŒ Error sending message:. {e}\")\n",
    "        answer = \"generate connection error with the remote server.\"\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"answer\": answer\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7066802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Receiving video via Whatsapp\n",
      "ğŸ¯ URL captured: https://f004.backblazeb2.com/file/temp-file-download/instances/3E06649A5C30D058DF6D4AEA87B09735/FCDFB5682420BF6E5A08AD2D67483975/1pZu7CtVa09Z9CQIP5hvVA==.mp4\n",
      "âœ… Video downloaded successfully.\n",
      "âœ… Video saved as input_video.mp4\n",
      "ğŸ§ª Processing video...\n",
      "Saving frame 0 how frames\\frame_0.jpg\n",
      "Saving frame 1 how frames\\frame_1.jpg\n",
      "Saving frame 2 how frames\\frame_2.jpg\n",
      "Saving frame 3 how frames\\frame_3.jpg\n",
      "Saving frame 4 how frames\\frame_4.jpg\n",
      "Saving frame 5 how frames\\frame_5.jpg\n",
      "Saving frame 6 how frames\\frame_6.jpg\n",
      "Saving frame 7 how frames\\frame_7.jpg\n",
      "Saving frame 8 how frames\\frame_8.jpg\n",
      "Saving frame 9 how frames\\frame_9.jpg\n",
      "Saving frame 10 how frames\\frame_10.jpg\n",
      "Saving frame 11 how frames\\frame_11.jpg\n",
      "Saving frame 12 how frames\\frame_12.jpg\n",
      "Saving frame 13 how frames\\frame_13.jpg\n",
      "Saving frame 14 how frames\\frame_14.jpg\n",
      "Saving frame 15 how frames\\frame_15.jpg\n",
      "Saving frame 16 how frames\\frame_16.jpg\n",
      "Saving frame 17 how frames\\frame_17.jpg\n",
      "Saving frame 18 how frames\\frame_18.jpg\n",
      "Saving frame 19 how frames\\frame_19.jpg\n",
      "Saving frame 20 how frames\\frame_20.jpg\n",
      "Saving frame 21 how frames\\frame_21.jpg\n",
      "Saving frame 22 how frames\\frame_22.jpg\n",
      "Saving frame 23 how frames\\frame_23.jpg\n",
      "Saving frame 24 how frames\\frame_24.jpg\n",
      "Saving frame 25 how frames\\frame_25.jpg\n",
      "Saving frame 26 how frames\\frame_26.jpg\n",
      "Saving frame 27 how frames\\frame_27.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for frames\\frame_0.jpg: [{'label': 'Real', 'score': 0.988437831401825}, {'label': 'Fake', 'score': 0.011562186293303967}]\n",
      "Deepfake score for frames\\frame_0.jpg: 0.011562186293303967\n",
      "Predictions for frames\\frame_1.jpg: [{'label': 'Real', 'score': 0.992716908454895}, {'label': 'Fake', 'score': 0.0072830417193472385}]\n",
      "Deepfake score for frames\\frame_1.jpg: 0.0072830417193472385\n",
      "Predictions for frames\\frame_10.jpg: [{'label': 'Real', 'score': 0.8464401364326477}, {'label': 'Fake', 'score': 0.15355980396270752}]\n",
      "Deepfake score for frames\\frame_10.jpg: 0.15355980396270752\n",
      "Predictions for frames\\frame_11.jpg: [{'label': 'Real', 'score': 0.8871473670005798}, {'label': 'Fake', 'score': 0.11285263299942017}]\n",
      "Deepfake score for frames\\frame_11.jpg: 0.11285263299942017\n",
      "Predictions for frames\\frame_12.jpg: [{'label': 'Real', 'score': 0.8533743023872375}, {'label': 'Fake', 'score': 0.14662566781044006}]\n",
      "Deepfake score for frames\\frame_12.jpg: 0.14662566781044006\n",
      "Predictions for frames\\frame_13.jpg: [{'label': 'Real', 'score': 0.8942188620567322}, {'label': 'Fake', 'score': 0.10578110814094543}]\n",
      "Deepfake score for frames\\frame_13.jpg: 0.10578110814094543\n",
      "Predictions for frames\\frame_14.jpg: [{'label': 'Real', 'score': 0.9404892325401306}, {'label': 'Fake', 'score': 0.059510789811611176}]\n",
      "Deepfake score for frames\\frame_14.jpg: 0.059510789811611176\n",
      "Predictions for frames\\frame_15.jpg: [{'label': 'Real', 'score': 0.9982328414916992}, {'label': 'Fake', 'score': 0.0017671644454821944}]\n",
      "Deepfake score for frames\\frame_15.jpg: 0.0017671644454821944\n",
      "Predictions for frames\\frame_16.jpg: [{'label': 'Real', 'score': 0.9982278943061829}, {'label': 'Fake', 'score': 0.0017720928881317377}]\n",
      "Deepfake score for frames\\frame_16.jpg: 0.0017720928881317377\n",
      "Predictions for frames\\frame_17.jpg: [{'label': 'Real', 'score': 0.9980055689811707}, {'label': 'Fake', 'score': 0.001994426129385829}]\n",
      "Deepfake score for frames\\frame_17.jpg: 0.001994426129385829\n",
      "Predictions for frames\\frame_18.jpg: [{'label': 'Real', 'score': 0.9716340899467468}, {'label': 'Fake', 'score': 0.028365887701511383}]\n",
      "Deepfake score for frames\\frame_18.jpg: 0.028365887701511383\n",
      "Predictions for frames\\frame_19.jpg: [{'label': 'Real', 'score': 0.8490133285522461}, {'label': 'Fake', 'score': 0.15098664164543152}]\n",
      "Deepfake score for frames\\frame_19.jpg: 0.15098664164543152\n",
      "Predictions for frames\\frame_2.jpg: [{'label': 'Real', 'score': 0.9943209886550903}, {'label': 'Fake', 'score': 0.005679015070199966}]\n",
      "Deepfake score for frames\\frame_2.jpg: 0.005679015070199966\n",
      "Predictions for frames\\frame_20.jpg: [{'label': 'Real', 'score': 0.8576924800872803}, {'label': 'Fake', 'score': 0.14230751991271973}]\n",
      "Deepfake score for frames\\frame_20.jpg: 0.14230751991271973\n",
      "Predictions for frames\\frame_21.jpg: [{'label': 'Real', 'score': 0.8502788543701172}, {'label': 'Fake', 'score': 0.1497211754322052}]\n",
      "Deepfake score for frames\\frame_21.jpg: 0.1497211754322052\n",
      "Predictions for frames\\frame_22.jpg: [{'label': 'Real', 'score': 0.9400526881217957}, {'label': 'Fake', 'score': 0.05994734540581703}]\n",
      "Deepfake score for frames\\frame_22.jpg: 0.05994734540581703\n",
      "Predictions for frames\\frame_23.jpg: [{'label': 'Real', 'score': 0.9273630380630493}, {'label': 'Fake', 'score': 0.07263699918985367}]\n",
      "Deepfake score for frames\\frame_23.jpg: 0.07263699918985367\n",
      "Predictions for frames\\frame_24.jpg: [{'label': 'Real', 'score': 0.8310574889183044}, {'label': 'Fake', 'score': 0.16894246637821198}]\n",
      "Deepfake score for frames\\frame_24.jpg: 0.16894246637821198\n",
      "Predictions for frames\\frame_25.jpg: [{'label': 'Real', 'score': 0.7202076315879822}, {'label': 'Fake', 'score': 0.2797924280166626}]\n",
      "Deepfake score for frames\\frame_25.jpg: 0.2797924280166626\n",
      "Predictions for frames\\frame_26.jpg: [{'label': 'Real', 'score': 0.5790870785713196}, {'label': 'Fake', 'score': 0.4209129214286804}]\n",
      "Deepfake score for frames\\frame_26.jpg: 0.4209129214286804\n",
      "Predictions for frames\\frame_27.jpg: [{'label': 'Real', 'score': 0.6218399405479431}, {'label': 'Fake', 'score': 0.3781600296497345}]\n",
      "Deepfake score for frames\\frame_27.jpg: 0.3781600296497345\n",
      "Predictions for frames\\frame_3.jpg: [{'label': 'Real', 'score': 0.9839766025543213}, {'label': 'Fake', 'score': 0.016023432835936546}]\n",
      "Deepfake score for frames\\frame_3.jpg: 0.016023432835936546\n",
      "Predictions for frames\\frame_4.jpg: [{'label': 'Real', 'score': 0.9970582723617554}, {'label': 'Fake', 'score': 0.0029417392797768116}]\n",
      "Deepfake score for frames\\frame_4.jpg: 0.0029417392797768116\n",
      "Predictions for frames\\frame_5.jpg: [{'label': 'Real', 'score': 0.8748193979263306}, {'label': 'Fake', 'score': 0.12518063187599182}]\n",
      "Deepfake score for frames\\frame_5.jpg: 0.12518063187599182\n",
      "Predictions for frames\\frame_6.jpg: [{'label': 'Real', 'score': 0.8705158233642578}, {'label': 'Fake', 'score': 0.12948419153690338}]\n",
      "Deepfake score for frames\\frame_6.jpg: 0.12948419153690338\n",
      "Predictions for frames\\frame_7.jpg: [{'label': 'Real', 'score': 0.7835379838943481}, {'label': 'Fake', 'score': 0.21646200120449066}]\n",
      "Deepfake score for frames\\frame_7.jpg: 0.21646200120449066\n",
      "Predictions for frames\\frame_8.jpg: [{'label': 'Real', 'score': 0.8259750008583069}, {'label': 'Fake', 'score': 0.17402495443820953}]\n",
      "Deepfake score for frames\\frame_8.jpg: 0.17402495443820953\n",
      "Predictions for frames\\frame_9.jpg: [{'label': 'Real', 'score': 0.8612950444221497}, {'label': 'Fake', 'score': 0.13870500028133392}]\n",
      "Deepfake score for frames\\frame_9.jpg: 0.13870500028133392\n",
      "ğŸ“¤ Generating the answer for the user....\n",
      "\n",
      "Final result:\n",
      "âš ï¸ Alert: possible manipulation detected..\n",
      "Reliability Index: 11 / 100\n",
      "Details: Average deepfake score: 0.12\n"
     ]
    }
   ],
   "source": [
    "# Graph construction\n",
    "workflow = StateGraph(GuardianState)\n",
    "\n",
    "workflow.add_node(\"receive_input\", receive_input)\n",
    "workflow.add_node(\"process_media\", process_media)\n",
    "workflow.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "workflow.set_entry_point(\"receive_input\")\n",
    "\n",
    "workflow.add_edge(\"receive_input\", \"process_media\")\n",
    "workflow.add_edge(\"process_media\", \"generate_answer\")\n",
    "workflow.add_edge(\"generate_answer\", END)\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "# Creating an empty starting state\n",
    "initial_state = {}\n",
    "\n",
    "# Executes the graph\n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "print(\"\\nFinal result:\")\n",
    "print(final_state[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf5b773",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
